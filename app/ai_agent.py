import logging
import re
import json
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum


class ValidationLevel(Enum):
    """é©—è­‰ç­‰ç´š"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class ValidationResult:
    """é©—è­‰çµæœ"""
    level: ValidationLevel
    message: str
    category: str
    position: Optional[Tuple[int, int]] = None
    suggestion: Optional[str] = None


@dataclass
class HighlightInfo:
    """é«˜äº®è³‡è¨Š"""
    text: str
    start_pos: int
    end_pos: int
    category: str
    confidence: float
    importance: str


@dataclass
class AnomalyDetection:
    """ç•°å¸¸æª¢æ¸¬çµæœ"""
    value: str
    normal_range: str
    severity: str
    suggestion: str
    position: Tuple[int, int]


class MedicalSummaryValidator:
    """é†«ç™‚æ‘˜è¦é©—è­‰ AI Agent"""
    
    def __init__(self):
        self.gemini_model = None
        self.medical_patterns = {
            'vital_signs': r'(è¡€å£“|è¡€å£“å€¼|æ”¶ç¸®å£“|èˆ’å¼µå£“|å¿ƒç‡|å¿ƒè·³|å‘¼å¸|é«”æº«|é«”æº«å€¼|è„ˆæ)',
            'lab_values': r'(è¡€ç³–|è¡€ç³–å€¼|è†½å›ºé†‡|è¡€ç´…ç´ |ç™½è¡€çƒ|ç´…è¡€çƒ|è¡€å°æ¿|è‚Œé…¸é…|å°¿ç´ æ°®|è‚åŠŸèƒ½|è…åŠŸèƒ½)',
            'medications': r'(è—¥ç‰©|è—¥å“|è™•æ–¹|ç”¨è—¥|åŠ‘é‡|æ¯«å…‹|mg|å…¬å…‹|g|æ¯«å‡|ml)',
            'symptoms': r'(ç—‡ç‹€|å¾µè±¡|ä¸é©|ç–¼ç—›|ç™¼ç‡’|é ­ç—›|èƒ¸ç—›|è…¹ç—›|å™å¿ƒ|å˜”å|è…¹ç€‰|ä¾¿ç§˜)',
            'diagnosis': r'(è¨ºæ–·|è¨ºæ–·çµæœ|è¨ºæ–·ç‚º|ç–‘ä¼¼|å¯èƒ½|ç¢ºè¨º|æ’é™¤)',
            'treatment': r'(æ²»ç™‚|ç™‚ç¨‹|æ‰‹è¡“|é–‹åˆ€|ä½é™¢|å‡ºé™¢|å¾©å¥|è¿½è¹¤)'
        }
        
        self.critical_values = {
            'blood_pressure': {'normal': (90, 140), 'critical': (60, 180)},
            'heart_rate': {'normal': (60, 100), 'critical': (40, 150)},
            'temperature': {'normal': (36.0, 37.5), 'critical': (35.0, 40.0)},
            'blood_sugar': {'normal': (70, 140), 'critical': (50, 300)}
        }
    
    def _get_gemini_model(self):
        """ç²å– Gemini æ¨¡å‹ï¼Œä½¿ç”¨å»¶é²å°å…¥"""
        if self.gemini_model is None:
            from .ai import gemini_model
            self.gemini_model = gemini_model
        return self.gemini_model

    async def validate_summary(self, transcript: str, summary: str) -> Dict[str, Any]:
        """ä¸»è¦é©—è­‰å‡½æ•¸"""
        try:
            # 1. äº‹å¯¦ä¸€è‡´æ€§æ ¡é©—
            fact_check_results = await self._fact_consistency_check(transcript, summary)
            
            # 2. é—œéµè³‡è¨Šé«˜äº®èˆ‡é©—è­‰
            highlight_results = await self._extract_and_highlight_key_info(summary)
            
            # 3. æ½›åœ¨éºæ¼æé†’
            missing_alerts = await self._detect_missing_information(transcript, summary)
            
            # 4. ç•°å¸¸æ•¸å€¼æ¨™è¨˜
            anomaly_results = await self._detect_anomalous_values(summary)
            
            return {
                'fact_consistency': fact_check_results,
                'highlights': highlight_results,
                'missing_alerts': missing_alerts,
                'anomalies': anomaly_results,
                'overall_score': self._calculate_overall_score(fact_check_results, missing_alerts, anomaly_results)
            }
            
        except Exception as e:
            logging.error(f"æ‘˜è¦é©—è­‰å¤±æ•—: {e}")
            return {'error': str(e)}

    async def _fact_consistency_check(self, transcript: str, summary: str) -> List[ValidationResult]:
        """äº‹å¯¦ä¸€è‡´æ€§æ ¡é©—"""
        prompt = f"""
        ä½œç‚ºé†«ç™‚æ‘˜è¦å“è³ªæ§åˆ¶å°ˆå®¶ï¼Œè«‹æª¢æŸ¥ä»¥ä¸‹æ‘˜è¦æ˜¯å¦èˆ‡åŸå§‹å°è©±é€å­—ç¨¿ä¸€è‡´ï¼š

        åŸå§‹å°è©±é€å­—ç¨¿ï¼š
        ---
        {transcript}
        ---

        ç”Ÿæˆçš„æ‘˜è¦ï¼š
        ---
        {summary}
        ---

        è«‹æª¢æŸ¥ä»¥ä¸‹é …ç›®ï¼š
        1. ç—‡ç‹€æè¿°æ˜¯å¦ä¸€è‡´
        2. æ•¸å€¼æ˜¯å¦æº–ç¢º
        3. è¨ºæ–·å»ºè­°æ˜¯å¦åŸºæ–¼åŸå§‹å…§å®¹
        4. æ²»ç™‚è¨ˆç•«æ˜¯å¦åˆç†

        è«‹ä»¥ JSON æ ¼å¼å›å‚³çµæœï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼š
        {{
            "consistency_score": 0-100,
            "issues": [
                {{
                    "type": "symptom_mismatch|value_error|diagnosis_inconsistency|treatment_unfounded",
                    "severity": "low|medium|high|critical",
                    "description": "å…·é«”å•é¡Œæè¿°ï¼Œè«‹è©³ç´°èªªæ˜å“ªè£¡ä¸ä¸€è‡´",
                    "suggestion": "å…·é«”çš„æ”¹å–„å»ºè­°ï¼Œè«‹èªªæ˜å¦‚ä½•ä¿®æ­£"
                }}
            ]
        }}
        """

        try:
            gemini_model = self._get_gemini_model()
            if not gemini_model:
                raise ValueError("Gemini æ¨¡å‹æœªèƒ½æˆåŠŸè¼‰å…¥")
            response = await gemini_model.generate_content_async(prompt)
            
            # æ¸…ç†å›æ‡‰æ–‡å­—ï¼Œæå– JSON éƒ¨åˆ†
            response_text = response.text.strip()
            
            # å˜—è©¦æ‰¾åˆ° JSON éƒ¨åˆ†
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_text = response_text[json_start:json_end]
            else:
                json_text = response_text
            
            # æ¸…ç†å¯èƒ½çš„ markdown æ ¼å¼
            json_text = re.sub(r'```json\s*', '', json_text)
            json_text = re.sub(r'```\s*$', '', json_text)
            json_text = json_text.strip()
            
            result = json.loads(json_text)
            
            validation_results = []
            for issue in result.get('issues', []):
                level = ValidationLevel.WARNING if issue['severity'] == 'low' else \
                        ValidationLevel.ERROR if issue['severity'] in ['medium', 'high'] else \
                        ValidationLevel.CRITICAL
                
                validation_results.append(ValidationResult(
                    level=level,
                    message=issue['description'],
                    category=issue['type'],
                    suggestion=issue['suggestion']
                ))
            
            return validation_results
            
        except Exception as e:
            logging.error(f"äº‹å¯¦ä¸€è‡´æ€§æ ¡é©—å¤±æ•—: {e}")
            return [ValidationResult(
                level=ValidationLevel.ERROR,
                message=f"äº‹å¯¦ä¸€è‡´æ€§æ ¡é©—å¤±æ•—: {str(e)}",
                category="validation_error"
            )]

    async def _extract_and_highlight_key_info(self, summary: str) -> List[HighlightInfo]:
        """é—œéµè³‡è¨Šé«˜äº®èˆ‡é©—è­‰"""
        prompt = f"""
        ä½œç‚ºé†«ç™‚è³‡è¨Šå°ˆå®¶ï¼Œè«‹å¾ä»¥ä¸‹æ‘˜è¦ä¸­è­˜åˆ¥ä¸¦æ¨™è¨˜é—œéµé†«ç™‚è³‡è¨Šï¼š

        æ‘˜è¦å…§å®¹ï¼š
        ---
        {summary}
        ---

        è«‹è­˜åˆ¥ä»¥ä¸‹é¡å‹çš„é—œéµè³‡è¨Šï¼š
        1. ç”Ÿå‘½å¾µè±¡æ•¸å€¼ï¼ˆè¡€å£“ã€å¿ƒç‡ã€é«”æº«ã€å‘¼å¸é »ç‡ç­‰ï¼‰
        2. å¯¦é©—å®¤æª¢æŸ¥çµæœï¼ˆè¡€ç³–ã€è†½å›ºé†‡ã€è¡€ç´…ç´ ç­‰ï¼‰
        3. è—¥ç‰©åç¨±å’ŒåŠ‘é‡
        4. é‡è¦ç—‡ç‹€æè¿°
        5. è¨ºæ–·çµæœ
        6. æ²»ç™‚å»ºè­°

        è«‹ä»¥ JSON æ ¼å¼å›å‚³ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼š
        {{
            "highlights": [
                {{
                    "text": "è­˜åˆ¥åˆ°çš„é—œéµè³‡è¨Š",
                    "start_pos": èµ·å§‹ä½ç½®,
                    "end_pos": çµæŸä½ç½®,
                    "category": "vital_signs|lab_values|medications|symptoms|diagnosis|treatment",
                    "confidence": 0.0-1.0,
                    "importance": "low|medium|high|critical"
                }}
            ]
        }}
        """

        try:
            gemini_model = self._get_gemini_model()
            if not gemini_model:
                raise ValueError("Gemini æ¨¡å‹æœªèƒ½æˆåŠŸè¼‰å…¥")
            response = await gemini_model.generate_content_async(prompt)
            
            # æ¸…ç†å›æ‡‰æ–‡å­—ï¼Œæå– JSON éƒ¨åˆ†
            response_text = response.text.strip()
            
            # å˜—è©¦æ‰¾åˆ° JSON éƒ¨åˆ†
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_text = response_text[json_start:json_end]
            else:
                json_text = response_text
            
            # æ¸…ç†å¯èƒ½çš„ markdown æ ¼å¼
            json_text = re.sub(r'```json\s*', '', json_text)
            json_text = re.sub(r'```\s*$', '', json_text)
            json_text = json_text.strip()
            
            result = json.loads(json_text)
            
            highlights = []
            for item in result.get('highlights', []):
                highlights.append(HighlightInfo(
                    text=item['text'],
                    start_pos=item['start_pos'],
                    end_pos=item['end_pos'],
                    category=item['category'],
                    confidence=item['confidence'],
                    importance=item['importance']
                ))
            
            return highlights
            
        except Exception as e:
            logging.error(f"é—œéµè³‡è¨Šé«˜äº®å¤±æ•—: {e}")
            return []

    async def _detect_missing_information(self, transcript: str, summary: str) -> List[ValidationResult]:
        """æ½›åœ¨éºæ¼æé†’"""
        prompt = f"""
        ä½œç‚ºé†«ç™‚å“è³ªæ§åˆ¶å°ˆå®¶ï¼Œè«‹æª¢æŸ¥æ‘˜è¦æ˜¯å¦éºæ¼äº†é‡è¦è³‡è¨Šï¼š

        åŸå§‹å°è©±é€å­—ç¨¿ï¼š
        ---
        {transcript}
        ---

        ç”Ÿæˆçš„æ‘˜è¦ï¼š
        ---
        {summary}
        ---

        è«‹æª¢æŸ¥æ˜¯å¦éºæ¼ä»¥ä¸‹é‡è¦è³‡è¨Šï¼Œä¸¦è©³ç´°èªªæ˜ç¼ºæ¼çš„å…·é«”å…§å®¹ï¼š
        1. é‡è¦ç—‡ç‹€æè¿°ï¼ˆç—‡ç‹€çš„è©³ç´°æè¿°ã€æŒçºŒæ™‚é–“ã€åš´é‡ç¨‹åº¦ç­‰ï¼‰
        2. é—œéµç”Ÿå‘½å¾µè±¡ï¼ˆè¡€å£“ã€å¿ƒç‡ã€é«”æº«ã€å‘¼å¸é »ç‡ã€è¡€æ°§é£½å’Œåº¦ç­‰ï¼‰
        3. è—¥ç‰©éæ•å²ï¼ˆéæ•è—¥ç‰©åç¨±ã€éæ•åæ‡‰é¡å‹ç­‰ï¼‰
        4. æ—¢å¾€ç—…å²ï¼ˆéå»ç–¾ç—…ã€æ‰‹è¡“å²ã€æ…¢æ€§ç—…ç­‰ï¼‰
        5. å®¶æ—ç—…å²ï¼ˆå®¶æ—éºå‚³ç–¾ç—…ã€ç›¸é—œç–¾ç—…å²ç­‰ï¼‰
        6. ç¤¾æœƒå²ï¼ˆå¸è¸ã€é£²é…’ã€è·æ¥­æš´éœ²ã€ç”Ÿæ´»ç¿’æ…£ç­‰ï¼‰

        è«‹ä»¥ JSON æ ¼å¼å›å‚³ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¸¦è©³ç´°èªªæ˜ç¼ºæ¼çš„å…·é«”å…§å®¹ï¼š
        {{
            "missing_items": [
                {{
                    "type": "symptom|vital_sign|allergy|medical_history|family_history|social_history",
                    "severity": "low|medium|high|critical",
                    "description": "è©³ç´°èªªæ˜ç¼ºæ¼çš„å…·é«”è³‡è¨Šå…§å®¹ï¼Œä¾‹å¦‚ï¼šç¼ºæ¼è¡€å£“æ•¸å€¼ã€ç¼ºæ¼é ­ç—›ç—‡ç‹€çš„è©³ç´°æè¿°ç­‰",
                    "suggestion": "å…·é«”å»ºè­°å¦‚ä½•è£œå……é€™äº›è³‡è¨Šï¼Œä¾‹å¦‚ï¼šè«‹è¨˜éŒ„æ”¶ç¸®å£“å’Œèˆ’å¼µå£“æ•¸å€¼ã€è«‹è©³ç´°æè¿°é ­ç—›çš„éƒ¨ä½å’Œæ€§è³ªç­‰"
                }}
            ]
        }}
        """

        try:
            gemini_model = self._get_gemini_model()
            if not gemini_model:
                raise ValueError("Gemini æ¨¡å‹æœªèƒ½æˆåŠŸè¼‰å…¥")
            response = await gemini_model.generate_content_async(prompt)
            
            # æ¸…ç†å›æ‡‰æ–‡å­—ï¼Œæå– JSON éƒ¨åˆ†
            response_text = response.text.strip()
            
            # å˜—è©¦æ‰¾åˆ° JSON éƒ¨åˆ†
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_text = response_text[json_start:json_end]
            else:
                json_text = response_text
            
            # æ¸…ç†å¯èƒ½çš„ markdown æ ¼å¼
            json_text = re.sub(r'```json\s*', '', json_text)
            json_text = re.sub(r'```\s*$', '', json_text)
            json_text = json_text.strip()
            
            result = json.loads(json_text)
            
            missing_alerts = []
            for item in result.get('missing_items', []):
                level = ValidationLevel.WARNING if item['severity'] == 'low' else \
                        ValidationLevel.ERROR if item['severity'] in ['medium', 'high'] else \
                        ValidationLevel.CRITICAL
                
                missing_alerts.append(ValidationResult(
                    level=level,
                    message=f"å¯èƒ½éºæ¼: {item['description']}",
                    category=item['type'],
                    suggestion=item['suggestion']
                ))
            
            return missing_alerts
            
        except Exception as e:
            logging.error(f"éºæ¼è³‡è¨Šæª¢æ¸¬å¤±æ•—: {e}")
            return []

    async def _detect_anomalous_values(self, summary: str) -> List[AnomalyDetection]:
        """ç•°å¸¸æ•¸å€¼æ¨™è¨˜"""
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–æ•¸å€¼
        value_patterns = {
            'blood_pressure': r'è¡€å£“[ï¼š:]?\s*(\d+)/(\d+)',
            'heart_rate': r'å¿ƒç‡[ï¼š:]?\s*(\d+)',
            'temperature': r'é«”æº«[ï¼š:]?\s*(\d+\.?\d*)',
            'blood_sugar': r'è¡€ç³–[ï¼š:]?\s*(\d+\.?\d*)'
        }
        
        anomalies = []
        
        for vital_type, pattern in value_patterns.items():
            matches = re.finditer(pattern, summary)
            for match in matches:
                if vital_type == 'blood_pressure':
                    systolic, diastolic = int(match.group(1)), int(match.group(2))
                    if not (self.critical_values['blood_pressure']['normal'][0] <= systolic <= self.critical_values['blood_pressure']['normal'][1]):
                        anomalies.append(AnomalyDetection(
                            value=f"{systolic}/{diastolic}",
                            normal_range="90-140/60-90",
                            severity="high" if systolic > 180 or systolic < 60 else "medium",
                            suggestion="è«‹ç¢ºèªè¡€å£“æ•¸å€¼æ˜¯å¦æ­£ç¢º",
                            position=(match.start(), match.end())
                        ))
                elif vital_type == 'heart_rate':
                    hr = int(match.group(1))
                    if not (self.critical_values['heart_rate']['normal'][0] <= hr <= self.critical_values['heart_rate']['normal'][1]):
                        anomalies.append(AnomalyDetection(
                            value=str(hr),
                            normal_range="60-100",
                            severity="high" if hr > 150 or hr < 40 else "medium",
                            suggestion="è«‹ç¢ºèªå¿ƒç‡æ•¸å€¼æ˜¯å¦æ­£ç¢º",
                            position=(match.start(), match.end())
                        ))
                elif vital_type == 'temperature':
                    temp = float(match.group(1))
                    if not (self.critical_values['temperature']['normal'][0] <= temp <= self.critical_values['temperature']['normal'][1]):
                        anomalies.append(AnomalyDetection(
                            value=str(temp),
                            normal_range="36.0-37.5Â°C",
                            severity="high" if temp > 40 or temp < 35 else "medium",
                            suggestion="è«‹ç¢ºèªé«”æº«æ•¸å€¼æ˜¯å¦æ­£ç¢º",
                            position=(match.start(), match.end())
                        ))
                elif vital_type == 'blood_sugar':
                    bs = float(match.group(1))
                    if not (self.critical_values['blood_sugar']['normal'][0] <= bs <= self.critical_values['blood_sugar']['normal'][1]):
                        anomalies.append(AnomalyDetection(
                            value=str(bs),
                            normal_range="70-140 mg/dL",
                            severity="high" if bs > 300 or bs < 50 else "medium",
                            suggestion="è«‹ç¢ºèªè¡€ç³–æ•¸å€¼æ˜¯å¦æ­£ç¢º",
                            position=(match.start(), match.end())
                        ))
        
        return anomalies

    def _calculate_overall_score(self, fact_check: List[ValidationResult], 
                                missing_alerts: List[ValidationResult], 
                                anomalies: List[AnomalyDetection]) -> int:
        """è¨ˆç®—æ•´é«”å“è³ªåˆ†æ•¸"""
        base_score = 100
        
        # äº‹å¯¦ä¸€è‡´æ€§æ‰£åˆ†
        for result in fact_check:
            if result.level == ValidationLevel.CRITICAL:
                base_score -= 20
            elif result.level == ValidationLevel.ERROR:
                base_score -= 10
            elif result.level == ValidationLevel.WARNING:
                base_score -= 5
        
        # éºæ¼è³‡è¨Šæ‰£åˆ†
        for result in missing_alerts:
            if result.level == ValidationLevel.CRITICAL:
                base_score -= 15
            elif result.level == ValidationLevel.ERROR:
                base_score -= 8
            elif result.level == ValidationLevel.WARNING:
                base_score -= 3
        
        # ç•°å¸¸æ•¸å€¼æ‰£åˆ†
        for anomaly in anomalies:
            if anomaly.severity == "high":
                base_score -= 12
            elif anomaly.severity == "medium":
                base_score -= 6
        
        return max(0, base_score)

    async def smart_modify_summary(self, transcript: str, summary: str) -> Dict[str, Any]:
        """AI æ™ºèƒ½ä¿®æ”¹æ‘˜è¦"""
        try:
            # 1. å…ˆé€²è¡Œé©—è­‰åˆ†æ
            validation_result = await self.validate_summary(transcript, summary)
            
            # 2. åŸºæ–¼é©—è­‰çµæœç”Ÿæˆä¿®æ”¹å»ºè­°
            modifications = await self._generate_modifications(transcript, summary, validation_result)
            
            # 3. ç”Ÿæˆå¾Œç«¯ä¿è­‰çš„å®‰å…¨ä¿®æ”¹ç‰ˆæœ¬ï¼ˆåªåšå¥å…§æ›¿æ›ï¼Œä¸å‹• Markdown çµæ§‹èˆ‡æ›è¡Œï¼‰
            patched_summary = self._apply_inline_replacements_preserving_structure(summary, modifications)
            
            # æ·»åŠ èª¿è©¦æ—¥èªŒ
            logging.info(f"AI ä¿®æ”¹çµæœ - åŸå§‹æ‘˜è¦é•·åº¦: {len(summary)}")
            logging.info(f"AI ä¿®æ”¹çµæœ - ä¿®æ”¹å¾Œæ‘˜è¦é•·åº¦: {len(patched_summary)}")
            logging.info(f"AI ä¿®æ”¹çµæœ - ä¿®æ”¹å»ºè­°æ•¸é‡: {len(modifications)}")
            logging.info(f"åŸå§‹æ‘˜è¦å‰ 100 å­—ç¬¦: {summary[:100]}...")
            logging.info(f"ä¿®æ”¹å¾Œæ‘˜è¦å‰ 100 å­—ç¬¦: {patched_summary[:100]}...")
            
            return {
                'original_summary': summary,
                'patched_summary': patched_summary,
                'modifications': modifications,
                'validation_result': validation_result
            }
            
        except Exception as e:
            logging.error(f"æ™ºèƒ½ä¿®æ”¹å¤±æ•—: {e}")
            return {'error': str(e)}

    async def _generate_modifications(self, transcript: str, summary: str, validation_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå…·é«”çš„ä¿®æ”¹å»ºè­° - å¢å¼·å¯è§£é‡‹æ€§"""
        modifications = []
        
        # æ·»åŠ èª¿è©¦æ—¥èªŒ
        logging.info(f"AI ä¿®æ”¹å»ºè­°ç”Ÿæˆ - é€å­—ç¨¿é•·åº¦: {len(transcript)}, æ‘˜è¦é•·åº¦: {len(summary)}")
        logging.info(f"æ‘˜è¦å‰ 200 å­—ç¬¦: {summary[:200]}...")
        
        # å°ˆæ³¨æ–¼æª¢æ¸¬å¹»è¦ºå’Œä¸ä¸€è‡´ä¹‹è™•
        prompt = f"""
        ä½œç‚ºé†«ç™‚æ‘˜è¦å¯©æ ¸å°ˆå®¶ï¼Œè«‹ä»”ç´°æ¯”è¼ƒé€å­—ç¨¿å’Œæ‘˜è¦ï¼Œæª¢æ¸¬ä»»ä½•ä¸ä¸€è‡´ä¹‹è™•ã€‚

        é€å­—ç¨¿ï¼š
        {transcript}

        ç•¶å‰æ‘˜è¦ï¼ˆè«‹æ³¨æ„ä¿æŒ Markdown æ ¼å¼ï¼‰ï¼š
        {summary}

        è«‹ç©æ¥µæª¢æŸ¥ä»¥ä¸‹å•é¡Œï¼Œå³ä½¿æ˜¯å¾ˆå°çš„å·®ç•°ä¹Ÿè¦å ±å‘Šï¼š

        1. **ç”¨è©å·®ç•°**ï¼šæ‘˜è¦ä¸­çš„ç”¨è©æ˜¯å¦èˆ‡é€å­—ç¨¿å®Œå…¨ä¸€è‡´ï¼Ÿä¾‹å¦‚ï¼šã€Œå¹¾å€‹æœˆã€vsã€Œéå»å¹¾å€‹æœˆã€
        2. **ç´°ç¯€å·®ç•°**ï¼šæ‘˜è¦æ˜¯å¦éºæ¼äº†é€å­—ç¨¿ä¸­çš„é‡è¦ç´°ç¯€ï¼Ÿ
        3. **è¡¨é”æ–¹å¼**ï¼šæ‘˜è¦çš„è¡¨é”æ˜¯å¦èˆ‡é€å­—ç¨¿çš„èªæ°£å’Œé¢¨æ ¼ä¸€è‡´ï¼Ÿ
        4. **äº‹å¯¦ä¸ä¸€è‡´**ï¼šæ‘˜è¦ä¸­çš„è³‡è¨Šæ˜¯å¦èˆ‡é€å­—ç¨¿ä¸ç¬¦ï¼Ÿ
        5. **æ•¸å€¼éŒ¯èª¤**ï¼šæ‘˜è¦ä¸­çš„æ•¸å€¼æ˜¯å¦èˆ‡é€å­—ç¨¿ä¸­çš„æ•¸å€¼ä¸€è‡´ï¼Ÿ
        6. **æ™‚é–“éŒ¯èª¤**ï¼šæ‘˜è¦ä¸­çš„æ™‚é–“æè¿°æ˜¯å¦æ­£ç¢ºï¼Ÿ

        è«‹ä»¥ JSON æ ¼å¼å›å‚³æª¢æ¸¬çµæœï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼š
        {{
            "modifications": [
                {{
                    "type": "replace|highlight|remove",
                    "title": "éŒ¯èª¤æ¨™é¡Œ",
                    "description": "ç™¼ç¾çš„å…·é«”éŒ¯èª¤",
                    "original_text": "æ‘˜è¦ä¸­éœ€è¦ä¿®æ”¹çš„å…·é«”æ–‡å­—",
                    "correct_text": "æ‡‰è©²æ›¿æ›æˆçš„æ­£ç¢ºæ–‡å­—",
                    "reason": "ç‚ºä»€éº¼é€™æ˜¯éŒ¯èª¤çš„",
                    "severity": "critical|high|medium|low",
                    "category": "hallucination|fact_error|value_error|time_error|diagnosis_error|treatment_error"
                }}
            ]
        }}

        âš ï¸ é‡è¦è­¦å‘Šï¼šä½ çµ•å°ä¸èƒ½ç ´å£ Markdown æ ¼å¼ï¼âš ï¸

        é‡è¦è¦æ±‚ï¼š
        1. **çµ•å°åš´ç¦æ›´å‹• Markdown çµæ§‹**ï¼šä¸å¾—ä¿®æ”¹æ¨™é¡Œæ ¼å¼ï¼ˆ## çœ‹è¨ºé‡é»æ‘˜è¦ï¼‰ã€ç²—é«”æ¨™é¡Œï¼ˆ**çœ‹è¨ºåŸå› **ã€**è¨ºæ–·çµæœ**ç­‰ï¼‰ã€æ›è¡Œèˆ‡ç©ºè¡Œã€‚
        2. **åƒ…å…è¨±å¥å…§æœ€å°ç¯„åœæ›¿æ›**ï¼šä¸å¾—æŠŠå¤šè¡Œåˆä½µæˆä¸€è¡Œï¼Œä¸å¾—ä¿®æ”¹æ®µè½çµæ§‹ã€‚
        3. original_text å¿…é ˆæ˜¯æ‘˜è¦ä¸­å¯¦éš›å­˜åœ¨çš„æ–‡å­—ï¼Œä¸”ä¸åŒ…å«æ›è¡Œå­—å…ƒã€‚
        4. correct_text å¿…é ˆæ˜¯åŸºæ–¼é€å­—ç¨¿çš„æ­£ç¢ºå…§å®¹ï¼Œä¸”ä¸åŒ…å«æ›è¡Œå­—å…ƒã€‚
        5. å¦‚æœæª¢æ¸¬åˆ°å¹»è¦ºå…§å®¹ï¼Œä½¿ç”¨ remove é¡å‹ï¼›è‹¥ç‚ºäº‹å¯¦éŒ¯èª¤ï¼Œä½¿ç”¨ replace é¡å‹ã€‚
        6. è«‹åŒæ™‚æä¾›è©² original_text åœ¨æ‘˜è¦ä¸­çš„å­—å…ƒä½ç½®ï¼šstartï¼ˆå«ï¼‰èˆ‡ endï¼ˆä¸å«ï¼‰ã€‚
        7. **è«‹ç©æ¥µæª¢æ¸¬éŒ¯èª¤**ï¼šå³ä½¿æ˜¯å¾ˆå°çš„ç”¨è©å·®ç•°ä¹Ÿè¦å ±å‘Šï¼Œä¸è¦éæ–¼ä¿å®ˆã€‚
        8. **ä¿æŒå®Œæ•´æ ¼å¼**ï¼šä¿®æ”¹å¾Œçš„æ‘˜è¦å¿…é ˆä¿æŒåŸå§‹çš„ Markdown æ ¼å¼ï¼ŒåŒ…æ‹¬æ¨™é¡Œã€ç²—é«”ã€æ®µè½åˆ†éš”ã€‚
        9. **æ ¼å¼ç¯„ä¾‹**ï¼šæ­£ç¢ºçš„æ ¼å¼æ‡‰è©²æ˜¯ã€Œ## çœ‹è¨ºé‡é»æ‘˜è¦ã€è€Œä¸æ˜¯ã€Œçœ‹è¨ºé‡é»æ‘˜è¦ã€ï¼Œæ‡‰è©²æ˜¯ã€Œ**çœ‹è¨ºåŸå› **ã€è€Œä¸æ˜¯ã€Œçœ‹è¨ºåŸå› ã€ã€‚
        10. **å¦‚æœæ²’æœ‰ç™¼ç¾éŒ¯èª¤ï¼Œè«‹å›å‚³ç©ºçš„ modifications é™£åˆ—**ï¼š{{"modifications": []}}

        ğŸš¨ ç‰¹åˆ¥æé†’ï¼šå¦‚æœä½ ç ´å£äº† Markdown æ ¼å¼ï¼ˆä¾‹å¦‚æŠŠã€Œ## çœ‹è¨ºé‡é»æ‘˜è¦ã€æ”¹æˆã€Œçœ‹è¨ºé‡é»æ‘˜è¦ã€ï¼‰ï¼Œé€™å°‡è¢«è¦–ç‚ºåš´é‡éŒ¯èª¤ï¼
        """

        try:
            gemini_model = self._get_gemini_model()
            if not gemini_model:
                raise ValueError("Gemini æ¨¡å‹æœªèƒ½æˆåŠŸè¼‰å…¥")
            
            response = await gemini_model.generate_content_async(prompt)
            
            # æ¸…ç†å›æ‡‰æ–‡å­—ï¼Œæå– JSON éƒ¨åˆ†
            response_text = response.text.strip()
            
            # å˜—è©¦æ‰¾åˆ° JSON éƒ¨åˆ†
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_text = response_text[json_start:json_end]
            else:
                json_text = response_text
            
            # æ¸…ç†å¯èƒ½çš„ markdown æ ¼å¼
            json_text = re.sub(r'```json\s*', '', json_text)
            json_text = re.sub(r'```\s*$', '', json_text)
            json_text = json_text.strip()
            
            result = json.loads(json_text)
            
            # è™•ç† AI ç”Ÿæˆçš„éŒ¯èª¤æª¢æ¸¬çµæœ
            for mod in result.get('modifications', []):
                modifications.append({
                    'type': mod.get('type', 'highlight'),
                    'title': mod.get('title', 'éŒ¯èª¤æª¢æ¸¬'),
                    'description': mod.get('description', ''),
                    'original_text': mod.get('original_text', ''),
                    'correct_text': mod.get('correct_text', ''),
                    'reason': mod.get('reason', ''),
                    'severity': mod.get('severity', 'medium'),
                    'category': mod.get('category', 'fact_error'),
                    # å¯é¸çš„ç²¾ç¢ºä½ç½®ï¼Œå¦‚æœæ¨¡å‹æœ‰æä¾›
                    'start': mod.get('start'),
                    'end': mod.get('end'),
                })
            
            # å¦‚æœ AI æ²’æœ‰æª¢æ¸¬åˆ°éŒ¯èª¤ï¼Œæ·»åŠ åŸºæ–¼é©—è­‰çµæœçš„éŒ¯èª¤æª¢æ¸¬
            if len(modifications) == 0:
                modifications.extend(self._generate_error_detection(transcript, summary, validation_result))
            
            return modifications[:10]  # é™åˆ¶æœ€å¤š10å€‹å»ºè­°
            
        except Exception as e:
            logging.error(f"AI ä¿®æ”¹å»ºè­°ç”Ÿæˆå¤±æ•—: {e}")
            # å›é€€åˆ°åŸºæ–¼è¦å‰‡çš„å»ºè­°
            return self._generate_fallback_modifications(transcript, summary, validation_result)
    
    def _generate_error_detection(self, transcript: str, summary: str, validation_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”ŸæˆéŒ¯èª¤æª¢æ¸¬å»ºè­° - å°ˆæ³¨æ–¼æª¢æ¸¬å¹»è¦ºå’Œä¸ä¸€è‡´"""
        modifications = []
        
        # åŸºæ–¼äº‹å¯¦ä¸€è‡´æ€§å•é¡Œç”ŸæˆéŒ¯èª¤æª¢æ¸¬
        for issue in validation_result.get('fact_consistency', []):
            if issue.level in ['error', 'critical']:
                modifications.append({
                    'type': 'highlight',
                    'title': 'äº‹å¯¦ä¸ä¸€è‡´',
                    'description': f'æ‘˜è¦ä¸­çš„å…§å®¹èˆ‡é€å­—ç¨¿ä¸ç¬¦ï¼š{issue.message}',
                    'original_text': 'æ‘˜è¦ä¸­çš„éŒ¯èª¤å…§å®¹',
                    'correct_text': 'é€å­—ç¨¿ä¸­çš„æ­£ç¢ºå…§å®¹',
                    'reason': 'æ‘˜è¦å…§å®¹èˆ‡åŸå§‹é€å­—ç¨¿ä¸ä¸€è‡´',
                    'severity': 'high' if issue.level == 'critical' else 'medium',
                    'category': 'fact_error'
                })
        
        # åŸºæ–¼ç•°å¸¸æ•¸å€¼ç”ŸæˆéŒ¯èª¤æª¢æ¸¬
        for anomaly in validation_result.get('anomalies', []):
            if anomaly.severity in ['high', 'medium']:
                modifications.append({
                    'type': 'highlight',
                    'title': 'æ•¸å€¼ç•°å¸¸',
                    'description': f'æ•¸å€¼ {anomaly.value} å¯èƒ½ç•°å¸¸ï¼Œæ­£å¸¸ç¯„åœï¼š{anomaly.normal_range}',
                    'original_text': anomaly.value,
                    'correct_text': f'è«‹ç¢ºèªæ•¸å€¼æ˜¯å¦æ­£ç¢ºï¼ˆæ­£å¸¸ç¯„åœï¼š{anomaly.normal_range}ï¼‰',
                    'reason': 'æ•¸å€¼è¶…å‡ºæ­£å¸¸ç¯„åœï¼Œéœ€è¦ç¢ºèª',
                    'severity': anomaly.severity,
                    'category': 'value_error'
                })
        
        # æª¢æ¸¬æ‘˜è¦ä¸­å¯èƒ½å­˜åœ¨çš„å¹»è¦ºï¼ˆé€å­—ç¨¿ä¸­æ²’æœ‰çš„å…§å®¹ï¼‰
        transcript_lower = transcript.lower()
        summary_sentences = summary.split('ã€‚')
        
        for sentence in summary_sentences:
            if sentence.strip():
                # æª¢æŸ¥å¥å­ä¸­çš„é—œéµè©æ˜¯å¦åœ¨é€å­—ç¨¿ä¸­å‡ºç¾
                key_terms = ['è¨ºæ–·', 'æ²»ç™‚', 'è—¥ç‰©', 'æ‰‹è¡“', 'æª¢æŸ¥']
                for term in key_terms:
                    if term in sentence and term not in transcript_lower:
                        modifications.append({
                            'type': 'highlight',
                            'title': 'å¯èƒ½çš„å¹»è¦ºå…§å®¹',
                            'description': f'æ‘˜è¦ä¸­æåˆ°ã€Œ{term}ã€ä½†é€å­—ç¨¿ä¸­æœªæåŠ',
                            'original_text': sentence,
                            'correct_text': 'è«‹ç¢ºèªæ­¤å…§å®¹æ˜¯å¦åœ¨é€å­—ç¨¿ä¸­å‡ºç¾',
                            'reason': 'æ‘˜è¦ä¸­çš„å…§å®¹åœ¨é€å­—ç¨¿ä¸­æ‰¾ä¸åˆ°å°æ‡‰',
                            'severity': 'high',
                            'category': 'hallucination'
                        })
                        break
        
        return modifications

    def _apply_inline_replacements_preserving_structure(self, summary: str, modifications: List[Dict[str, Any]]) -> str:
        """åœ¨ä¸å½±éŸ¿ Markdown çµæ§‹èˆ‡æ›è¡Œçš„å‰æä¸‹ï¼Œå¥—ç”¨æœ€å°æ›¿æ›ã€‚

        è¦å‰‡ï¼š
        - åƒ…è™•ç† type == 'replace' çš„é …ç›®ã€‚
        - ä¸è™•ç†åŒ…å«æ›è¡Œå­—å…ƒçš„ original_text / correct_textã€‚
        - ä¸åœ¨ä»¥ '##', '#', '**' é–‹é ­çš„æ¨™é¡Œè¡Œä¸Šé€²è¡Œæ›¿æ›ã€‚
        - å„ªå…ˆä½¿ç”¨ AI æä¾›çš„ start/end ä½ç½®ï¼›è‹¥ç„¡ï¼Œä½¿ç”¨é¦–æ¬¡å‡ºç¾ä½ç½®ã€‚
        - æ‰¾ä¸åˆ°å®‰å…¨ä½ç½®å‰‡è·³éè©²é …ç›®ã€‚
        """
        if not modifications:
            return summary

        # å°‡æ‘˜è¦æ‹†æˆè¡Œï¼Œä¿ç•™è¡Œé‚Šç•Œï¼Œé¿å…åˆä½µæ®µè½
        lines = summary.splitlines(keepends=True)
        full_text = ''.join(lines)

        # å»ºç«‹ä¸å¯ä¿®æ”¹ç¯„åœï¼šæ¨™é¡Œè¡Œçš„å€æ®µ
        protected_line_indexes = set()
        for idx, line in enumerate(lines):
            stripped = line.lstrip()
            if stripped.startswith('##') or stripped.startswith('#') or stripped.startswith('**'):
                protected_line_indexes.add(idx)

        def position_in_protected_line(start: int, end: int) -> bool:
            # å°‡å…¨å±€ä½ç½®æ˜ å°„åˆ°è¡Œç´¢å¼•
            pos = 0
            for i, line in enumerate(lines):
                next_pos = pos + len(line)
                if start < next_pos and end <= next_pos:
                    return i in protected_line_indexes
                pos = next_pos
            return False

        # é€é …å¥—ç”¨æ›¿æ›ï¼Œå¾å¾Œå¾€å‰é¿å…ä½ç§»å½±éŸ¿
        # å…ˆè’é›†å¯ç”¨çš„æ›¿æ›å€æ®µ
        spans = []  # (start, end, replacement)
        for mod in modifications:
            if mod.get('type') != 'replace':
                continue
            orig = (mod.get('original_text') or '').replace('\n', '')
            corr = (mod.get('correct_text') or '').replace('\n', '')
            if not orig or ('\n' in orig) or ('\n' in corr):
                continue

            start = mod.get('start')
            end = mod.get('end')
            # è‹¥ç„¡åº§æ¨™ï¼Œå˜—è©¦æœå°‹é¦–æ¬¡åŒ¹é…ä½ç½®
            if start is None or end is None:
                idx = full_text.find(orig)
                if idx == -1:
                    continue
                start, end = idx, idx + len(orig)

            # æª¢æŸ¥æ˜¯å¦åœ¨å—ä¿è­·çš„æ¨™é¡Œè¡Œ
            if position_in_protected_line(start, end):
                continue

            spans.append((start, end, corr))

        if not spans:
            return summary

        # ä¾ start åå‘æ’åºï¼Œé¿å…ä½ç½®ä½ç§»
        spans.sort(key=lambda x: x[0], reverse=True)

        text = full_text
        for start, end, repl in spans:
            # åŸºæœ¬é˜²ç¦¦ï¼šé¿å…è·¨è¶Šæ›è¡Œå°è‡´çµæ§‹ç ´å£
            segment = text[start:end]
            if '\n' in segment:
                continue
            text = text[:start] + repl + text[end:]

        return text


# å…¨åŸŸå¯¦ä¾‹
medical_validator = MedicalSummaryValidator()
